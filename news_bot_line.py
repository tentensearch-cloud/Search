import os
import json
import time
import feedparser
import logging
import sys
from pathlib import Path
from datetime import datetime
import utils
from line_client import LineClient

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

class NewsBotLine:
    def __init__(self):
        self.google_api_key = os.environ.get('GOOGLE_API_KEY')
        self.line_token = os.environ.get('LINE_CHANNEL_ACCESS_TOKEN')
        self.line_user_id = os.environ.get('LINE_USER_ID')
        self.rss_feeds = os.environ.get('RSS_FEEDS', '').split(',')
        
        self.history_file = Path('history.json')
        self.history = self.load_history()
        self.excluded_models = []
        
        self.line = LineClient(self.line_token, self.line_user_id)
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.model, self.model_name = utils.get_smart_gemini_model(
            self.google_api_key, excluded_models=self.excluded_models
        )

    def load_history(self):
        if self.history_file.exists():
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {"ids": [], "titles": []}
        return {"ids": [], "titles": []}

    def save_history(self):
        with open(self.history_file, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, ensure_ascii=False, indent=2)

    def fetch_new_entries(self):
        new_entries = []
        for url in self.rss_feeds:
            if not url: continue
            try:
                feed = feedparser.parse(url.strip())
                for entry in feed.entries:
                    entry_id = entry.get('id', entry.get('link'))
                    title = utils.clean_html_tags(entry.title)
                    
                    # IDé‡è¤‡ãƒã‚§ãƒƒã‚¯
                    if entry_id in self.history["ids"]:
                        continue
                    
                    # é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
                    if utils.is_similar(title, self.history.get("titles", [])):
                        logger.info(f"é¡ä¼¼è¨˜äº‹ã‚’ã‚¹ã‚­ãƒƒãƒ—: {title}")
                        self.history["ids"].append(entry_id) # ã‚¹ã‚­ãƒƒãƒ—ã—ãŸã‚‚ã®ã‚‚å†é€ã—ãªã„ã‚ˆã†è¨˜éŒ²
                        continue
                        
                    new_entries.append(entry)
            except Exception as e:
                logger.error(f"RSSå–å¾—ã‚¨ãƒ©ãƒ¼ ({url}): {e}")
        return new_entries

    def process_entry(self, entry):
        title = utils.clean_html_tags(entry.title)
        link = entry.link
        summary_text = utils.clean_html_tags(entry.get('summary', ''))
        
        logger.info(f"å‡¦ç†ä¸­: {title}")
        
        # ç·Šæ€¥åº¦åˆ¤å®š
        urgent = utils.is_urgent(title, summary_text)
        prefix = "ğŸš¨ã€ç·Šæ€¥ã€‘" if urgent else "ğŸ“Œã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘"
        
        prompt = utils.get_analyst_prompt(f"ã‚¿ã‚¤ãƒˆãƒ«: {title}\næœ¬æ–‡: {summary_text}\nURL: {link}")
        
        max_retries = 3
        for attempt in range(max_retries):
            if not self.model:
                self.model, self.model_name = utils.get_smart_gemini_model(
                    self.google_api_key, excluded_models=self.excluded_models
                )
            
            if not self.model:
                logger.error("åˆ©ç”¨å¯èƒ½ãªGeminiãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return None

            try:
                response = self.model.generate_content(prompt)
                result_text = response.text
                
                if "é™¤å¤–å¯¾è±¡" in result_text:
                    return None
                    
                full_message = f"{prefix}\n{title}\n\n{result_text}\n\nè¨˜äº‹URL: {link}"
                return full_message
            except Exception as e:
                error_str = str(e)
                logger.error(f"Geminiã‚¨ãƒ©ãƒ¼ ({self.model_name}): {e}")
                
                if "429" in error_str or "quota" in error_str.lower():
                    self.excluded_models.append(self.model_name)
                    self.model = None # æ¬¡ã®ãƒ«ãƒ¼ãƒ—ã§å†é¸æŠ
                    time.sleep(5)
                else:
                    time.sleep(2)
        return None

    def run(self):
        new_entries = self.fetch_new_entries()
        logger.info(f"æ–°è¦è¨˜äº‹: {len(new_entries)}ä»¶")
        
        for entry in new_entries:
            try:
                result = self.process_entry(entry)
                if result:
                    if self.line.send_message(result):
                        self.history["ids"].append(entry.get('id', entry.get('link')))
                        self.history["titles"].append(utils.clean_html_tags(entry.title))
                        # å±¥æ­´ãŒå¤§ãããªã‚Šã™ããªã„ã‚ˆã†èª¿æ•´ (ç›´è¿‘200ä»¶)
                        self.history["titles"] = self.history["titles"][-200:]
                        self.save_history()
                        time.sleep(5) # é€ä¿¡é–“éš”
            except Exception as e:
                logger.error(f"è¨˜äº‹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    bot = NewsBotLine()
    bot.run()
